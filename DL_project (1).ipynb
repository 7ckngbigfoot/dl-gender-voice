{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EohuzefVSicy",
        "outputId": "218738bf-32bc-4c3d-d64b-9d28db71c068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The operation couldn’t be completed. Unable to locate a Java Runtime.\n",
            "Please visit http://www.java.com for information on installing Java.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6_xiM_fTD4s",
        "outputId": "c41d8c60-4c91-4e99-d243-8f03dbd47a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyAudio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyAudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4-1iDYvyP4IY"
      },
      "outputs": [],
      "source": [
        "import pyaudio\n",
        "import os\n",
        "import wave\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jXxlEbMhQUq7"
      },
      "outputs": [],
      "source": [
        "from sys import byteorder\n",
        "from array import array\n",
        "from struct import pack\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmFxinTRXNpO"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQOyLtiAbjGE"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "Cev6niXyQbH9",
        "outputId": "eaa5c6b6-6816-4ce2-dd73-f2f0fd3f8e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples: 66938\n",
            "Number of male samples: 33469\n",
            "Number of female samples: 33469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 66938/66938 [00:12<00:00, 5562.31it/s]\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset from a CSV file\n",
        "dataset = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Determine the number of total, male, and female samples in the dataset\n",
        "total_samples = len(dataset)\n",
        "male_count = len(dataset[dataset['gender'] == 1])\n",
        "female_count = len(dataset[dataset['gender'] == 0])\n",
        "\n",
        "# Display the counts\n",
        "print(\"Total number of samples:\", total_samples)\n",
        "print(\"Number of male samples:\", male_count)\n",
        "print(\"Number of female samples:\", female_count)\n",
        "\n",
        "# Create an array to store 128 audio features for each sample\n",
        "X = np.zeros((total_samples, 128))\n",
        "\n",
        "# Create an array to store gender labels for each sample (1 for male, 0 for female)\n",
        "y = np.zeros((total_samples, 1))\n",
        "\n",
        "# Loop through each sample to extract features and labels\n",
        "for i, (file_name, gender_label) in tqdm.tqdm(enumerate(zip(dataset['filename'], dataset['gender'])), \"Loading data\", total=total_samples):\n",
        "    #feature_data = np.load(\"/content/gdrive/My Drive/\" + file_name)\n",
        "    feature_data = np.load(file_name)\n",
        "    X[i] = feature_data\n",
        "    y[i] = gender_label\n",
        "\n",
        "# Preprocess the feature data for neural network input\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X , dtype=np.float32, maxlen=144, padding='post')\n",
        "X = X.reshape(-1, 12, 12)\n",
        "X = np.expand_dims(X, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "bIrTfymqdLC_",
        "outputId": "5c3b5473-e05c-4073-8da9-aa9964107cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.7404141e-02 9.1459781e-02 3.6782688e-01 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [2.3867648e-04 1.0894923e-04 1.4831129e-04 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [2.9285662e-02 3.1437859e-02 7.6510203e-01 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " ...\n",
            " [6.2559600e-05 1.2894056e-04 1.7443823e-03 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [1.3852437e-02 2.2089299e-02 3.6699757e-02 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [7.8245113e-03 7.5188670e-03 2.2727162e-02 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]]\n",
            "(48195, 144)\n",
            "(48195, 128)\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "# Further split the training set into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=7)\n",
        "\n",
        "# Flatten each sequence in the training features\n",
        "X_flat = np.array([sequence.flatten() for sequence in X_train])\n",
        "\n",
        "# Display the first 10 flattened sequences and their shape\n",
        "#print(X_flat[:10])\n",
        "#print(X_flat.shape)\n",
        "\n",
        "# Convert flattened features to a DataFrame and drop the last 16 columns\n",
        "# that we added to make our records 2D from 1D\n",
        "X_flat = pd.DataFrame(X_flat)\n",
        "X_flat = X_flat.iloc[:, :-16]\n",
        "print(X_flat.shape)\n",
        "\n",
        "# Train a logistic regression model on the processed training data\n",
        "logreg = LogisticRegression(random_state=87, max_iter=100000).fit(X_flat, y_train.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "QjUUeO_Zd6bT",
        "outputId": "0c682007-9371-46d0-bf62-fcedce8007ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8001195100089632\n",
            "Training set accuracy: 0.7945\n",
            "Test set accuracy: 0.8001\n"
          ]
        }
      ],
      "source": [
        "# Flatten each sequence in the test features\n",
        "X_test_flat = np.array([sequence.flatten() for sequence in X_test])\n",
        "X_test_flat = pd.DataFrame(X_test_flat)\n",
        "X_test_flat = X_test_flat.iloc[:, :-16]\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_predtest = logreg.predict(X_test_flat)\n",
        "\n",
        "# Calculate the accuracy of the model on the test set\n",
        "accuracy_test = accuracy_score(y_test, y_predtest)\n",
        "print(accuracy_test)\n",
        "\n",
        "# Display the accuracy of the model on both the training and test sets\n",
        "print(\"Training set accuracy: {:.4f}\".format(logreg.score(X_flat, y_train.squeeze())))\n",
        "print(\"Test set accuracy: {:.4f}\".format(logreg.score(X_test_flat, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CNN 2D**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(64, 12, 12, 1)]         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (64, 10, 10, 128)         1280      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (64, 5, 5, 128)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (64, 4, 4, 256)           131328    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (64, 2, 2, 256)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (64, 2, 2, 512)           131584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (64, 1, 1, 512)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (64, 512)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (64, 1024)                525312    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (64, 1)                   1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 790529 (3.02 MB)\n",
            "Trainable params: 790529 (3.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# using binary crossentropy as it's male/female classification (binary)\n",
        "inputs = tf.keras.Input(shape=(X.shape[1], X.shape[2], X.shape[3]), batch_size = 64)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(128, 3, activation='relu')(inputs)\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(256, 2, activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(512, 1, activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
        "# print summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 0.5809 - val_accuracy: 0.9246\n",
            "Epoch 2/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0194 - accuracy: 0.9930 - val_loss: 0.6280 - val_accuracy: 0.9268\n",
            "Epoch 3/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.6379 - val_accuracy: 0.9313\n",
            "Epoch 4/100\n",
            "754/754 [==============================] - 7s 9ms/step - loss: 0.0282 - accuracy: 0.9918 - val_loss: 0.6935 - val_accuracy: 0.9281\n",
            "Epoch 5/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0301 - accuracy: 0.9914 - val_loss: 0.6159 - val_accuracy: 0.9283\n",
            "Epoch 6/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.7806 - val_accuracy: 0.9203\n",
            "Epoch 7/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.6387 - val_accuracy: 0.9292\n",
            "Epoch 8/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.7351 - val_accuracy: 0.9251\n",
            "Epoch 9/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.7207 - val_accuracy: 0.9333\n",
            "Epoch 10/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.8045 - val_accuracy: 0.9289\n",
            "Epoch 11/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.7413 - val_accuracy: 0.9298\n",
            "Epoch 12/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.6871 - val_accuracy: 0.9302\n",
            "Epoch 13/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.6496 - val_accuracy: 0.9294\n",
            "Epoch 14/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.7038 - val_accuracy: 0.9326\n",
            "Epoch 15/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.6991 - val_accuracy: 0.9296\n",
            "Epoch 16/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0392 - accuracy: 0.9907 - val_loss: 0.5885 - val_accuracy: 0.9313\n",
            "Epoch 17/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.6986 - val_accuracy: 0.9335\n",
            "Epoch 18/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.7553 - val_accuracy: 0.9298\n",
            "Epoch 19/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.8023 - val_accuracy: 0.9300\n",
            "Epoch 20/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.6171 - val_accuracy: 0.9255\n",
            "Epoch 21/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.6274 - val_accuracy: 0.9302\n",
            "Epoch 22/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.6619 - val_accuracy: 0.9289\n",
            "Epoch 23/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 0.7833 - val_accuracy: 0.9268\n",
            "Epoch 24/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0250 - accuracy: 0.9929 - val_loss: 0.7579 - val_accuracy: 0.9251\n",
            "Epoch 25/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.6751 - val_accuracy: 0.9283\n",
            "Epoch 26/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.6894 - val_accuracy: 0.9296\n",
            "Epoch 27/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.8416 - val_accuracy: 0.9281\n",
            "Epoch 28/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.7536 - val_accuracy: 0.9253\n",
            "Epoch 29/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.6011 - val_accuracy: 0.9253\n",
            "Epoch 30/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.8401 - val_accuracy: 0.9298\n",
            "Epoch 31/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.8026 - val_accuracy: 0.9313\n",
            "Epoch 32/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.7730 - val_accuracy: 0.9285\n",
            "Epoch 33/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.6260 - val_accuracy: 0.9219\n",
            "Epoch 34/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.7025 - val_accuracy: 0.9320\n",
            "Epoch 35/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.8236 - val_accuracy: 0.9277\n",
            "Epoch 36/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0234 - accuracy: 0.9933 - val_loss: 0.5915 - val_accuracy: 0.9279\n",
            "Epoch 37/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0256 - accuracy: 0.9929 - val_loss: 0.6544 - val_accuracy: 0.9294\n",
            "Epoch 38/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.7849 - val_accuracy: 0.9346\n",
            "Epoch 39/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.7106 - val_accuracy: 0.9266\n",
            "Epoch 40/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.7655 - val_accuracy: 0.9341\n",
            "Epoch 41/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 0.6519 - val_accuracy: 0.9240\n",
            "Epoch 42/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.6671 - val_accuracy: 0.9330\n",
            "Epoch 43/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.7875 - val_accuracy: 0.9266\n",
            "Epoch 44/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.6870 - val_accuracy: 0.9274\n",
            "Epoch 45/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0251 - accuracy: 0.9927 - val_loss: 1.0155 - val_accuracy: 0.9242\n",
            "Epoch 46/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.7522 - val_accuracy: 0.9274\n",
            "Epoch 47/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.6741 - val_accuracy: 0.9247\n",
            "Epoch 48/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.7276 - val_accuracy: 0.9264\n",
            "Epoch 49/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.9562 - val_accuracy: 0.9259\n",
            "Epoch 50/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.7555 - val_accuracy: 0.9261\n",
            "Epoch 51/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.6809 - val_accuracy: 0.9322\n",
            "Epoch 52/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.7148 - val_accuracy: 0.9292\n",
            "Epoch 53/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.9292 - val_accuracy: 0.9156\n",
            "Epoch 54/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.8817 - val_accuracy: 0.9261\n",
            "Epoch 55/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.8473 - val_accuracy: 0.9285\n",
            "Epoch 56/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.8054 - val_accuracy: 0.9324\n",
            "Epoch 57/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0087 - accuracy: 0.9966 - val_loss: 0.8317 - val_accuracy: 0.9302\n",
            "Epoch 58/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.8115 - val_accuracy: 0.9303\n",
            "Epoch 59/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.7714 - val_accuracy: 0.9317\n",
            "Epoch 60/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.8806 - val_accuracy: 0.9270\n",
            "Epoch 61/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.8252 - val_accuracy: 0.9234\n",
            "Epoch 62/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 0.6910 - val_accuracy: 0.9289\n",
            "Epoch 63/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.7338 - val_accuracy: 0.9330\n",
            "Epoch 64/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.9134 - val_accuracy: 0.9333\n",
            "Epoch 65/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.7532 - val_accuracy: 0.9313\n",
            "Epoch 66/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.7993 - val_accuracy: 0.9272\n",
            "Epoch 67/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.9208 - val_accuracy: 0.9309\n",
            "Epoch 68/100\n",
            "754/754 [==============================] - 7s 9ms/step - loss: 0.0256 - accuracy: 0.9929 - val_loss: 0.6726 - val_accuracy: 0.9331\n",
            "Epoch 69/100\n",
            "754/754 [==============================] - 6s 9ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.7786 - val_accuracy: 0.9315\n",
            "Epoch 70/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0302 - accuracy: 0.9922 - val_loss: 0.6640 - val_accuracy: 0.9290\n",
            "Epoch 71/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.7883 - val_accuracy: 0.9380\n",
            "Epoch 72/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.7590 - val_accuracy: 0.9272\n",
            "Epoch 73/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.7208 - val_accuracy: 0.9311\n",
            "Epoch 74/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.9633 - val_accuracy: 0.9231\n",
            "Epoch 75/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.7619 - val_accuracy: 0.9303\n",
            "Epoch 76/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.8040 - val_accuracy: 0.9302\n",
            "Epoch 77/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.8725 - val_accuracy: 0.9236\n",
            "Epoch 78/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.8231 - val_accuracy: 0.9296\n",
            "Epoch 79/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.8024 - val_accuracy: 0.9322\n",
            "Epoch 80/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 1.0251 - val_accuracy: 0.9326\n",
            "Epoch 81/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0276 - accuracy: 0.9925 - val_loss: 0.7757 - val_accuracy: 0.9255\n",
            "Epoch 82/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.7558 - val_accuracy: 0.9330\n",
            "Epoch 83/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.8688 - val_accuracy: 0.9270\n",
            "Epoch 84/100\n",
            "754/754 [==============================] - 7s 9ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.8319 - val_accuracy: 0.9232\n",
            "Epoch 85/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.9336 - val_accuracy: 0.9292\n",
            "Epoch 86/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.9208 - val_accuracy: 0.9322\n",
            "Epoch 87/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0195 - accuracy: 0.9955 - val_loss: 1.0441 - val_accuracy: 0.9277\n",
            "Epoch 88/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.7593 - val_accuracy: 0.9262\n",
            "Epoch 89/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.7780 - val_accuracy: 0.9259\n",
            "Epoch 90/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.9689 - val_accuracy: 0.9313\n",
            "Epoch 91/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.7377 - val_accuracy: 0.9317\n",
            "Epoch 92/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.9981 - val_accuracy: 0.9315\n",
            "Epoch 93/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.8490 - val_accuracy: 0.9307\n",
            "Epoch 94/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.8501 - val_accuracy: 0.9309\n",
            "Epoch 95/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.8461 - val_accuracy: 0.9309\n",
            "Epoch 96/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.7969 - val_accuracy: 0.9343\n",
            "Epoch 97/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.9274 - val_accuracy: 0.9330\n",
            "Epoch 98/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 0.7954 - val_accuracy: 0.9277\n",
            "Epoch 99/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0292 - accuracy: 0.9925 - val_loss: 0.8943 - val_accuracy: 0.9311\n",
            "Epoch 100/100\n",
            "754/754 [==============================] - 6s 8ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.9983 - val_accuracy: 0.9270\n",
            "Evaluating the model using 13388 samples...\n",
            "Loss: 0.9731\n",
            "Accuracy: 92.69%\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "# train the model using the training set and validating using validation set\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# save the model to a file\n",
        "\n",
        "#model.save(\"results/model.h5\")  \n",
        "\n",
        "# evaluating the model using the testing set\n",
        "print(f\"Evaluating the model using {len(X_test)} samples...\")\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(64, 12, 12, 1)]         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (64, 10, 10, 64)          640       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (64, 5, 5, 64)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (64, 4, 4, 128)           32896     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (64, 2, 2, 128)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (64, 2, 2, 256)           33024     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (64, 1, 1, 256)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (64, 256)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (64, 512)                 131584    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (64, 1)                   513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 198657 (776.00 KB)\n",
            "Trainable params: 198657 (776.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# using binary crossentropy as it's male/female classification (binary)\n",
        "inputs = tf.keras.Input(shape=(X.shape[1], X.shape[2], X.shape[3]), batch_size = 64)\n",
        "\n",
        "x2 = tf.keras.layers.Conv2D(64, 3, activation='relu')(inputs)\n",
        "x2 = tf.keras.layers.MaxPooling2D()(x2)\n",
        "\n",
        "x2 = tf.keras.layers.Conv2D(128, 2, activation='relu')(x2)\n",
        "x2 = tf.keras.layers.MaxPooling2D()(x2)\n",
        "\n",
        "x2 = tf.keras.layers.Conv2D(256, 1, activation='relu')(x2)\n",
        "x2 = tf.keras.layers.MaxPooling2D()(x2)\n",
        "\n",
        "x2 = tf.keras.layers.Flatten()(x2)\n",
        "\n",
        "x2 = tf.keras.layers.Dense(512, activation='relu')(x2)\n",
        "\n",
        "outputs2 = tf.keras.layers.Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "model2 = tf.keras.Model(inputs, outputs2)\n",
        "model2.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
        "# print summary of the model\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.4571 - accuracy: 0.7870 - val_loss: 0.3424 - val_accuracy: 0.8571\n",
            "Epoch 2/100\n",
            "754/754 [==============================] - 3s 5ms/step - loss: 0.3350 - accuracy: 0.8580 - val_loss: 0.2937 - val_accuracy: 0.8829\n",
            "Epoch 3/100\n",
            "754/754 [==============================] - 4s 5ms/step - loss: 0.2965 - accuracy: 0.8777 - val_loss: 0.3594 - val_accuracy: 0.8525\n",
            "Epoch 4/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.2788 - accuracy: 0.8860 - val_loss: 0.2715 - val_accuracy: 0.8835\n",
            "Epoch 5/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.2532 - accuracy: 0.8965 - val_loss: 0.2526 - val_accuracy: 0.8967\n",
            "Epoch 6/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.2390 - accuracy: 0.9036 - val_loss: 0.2247 - val_accuracy: 0.9092\n",
            "Epoch 7/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.2271 - accuracy: 0.9078 - val_loss: 0.2654 - val_accuracy: 0.8952\n",
            "Epoch 8/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.2129 - accuracy: 0.9142 - val_loss: 0.2434 - val_accuracy: 0.9100\n",
            "Epoch 9/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1994 - accuracy: 0.9214 - val_loss: 0.2133 - val_accuracy: 0.9167\n",
            "Epoch 10/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1947 - accuracy: 0.9224 - val_loss: 0.2055 - val_accuracy: 0.9223\n",
            "Epoch 11/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1874 - accuracy: 0.9266 - val_loss: 0.2190 - val_accuracy: 0.9203\n",
            "Epoch 12/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1772 - accuracy: 0.9293 - val_loss: 0.2057 - val_accuracy: 0.9216\n",
            "Epoch 13/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1751 - accuracy: 0.9319 - val_loss: 0.2157 - val_accuracy: 0.9210\n",
            "Epoch 14/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1682 - accuracy: 0.9338 - val_loss: 0.2255 - val_accuracy: 0.9137\n",
            "Epoch 15/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1557 - accuracy: 0.9386 - val_loss: 0.2280 - val_accuracy: 0.9199\n",
            "Epoch 16/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1513 - accuracy: 0.9406 - val_loss: 0.2847 - val_accuracy: 0.9081\n",
            "Epoch 17/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1440 - accuracy: 0.9439 - val_loss: 0.2113 - val_accuracy: 0.9219\n",
            "Epoch 18/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1368 - accuracy: 0.9475 - val_loss: 0.2265 - val_accuracy: 0.9255\n",
            "Epoch 19/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1317 - accuracy: 0.9485 - val_loss: 0.2415 - val_accuracy: 0.9190\n",
            "Epoch 20/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1301 - accuracy: 0.9487 - val_loss: 0.2228 - val_accuracy: 0.9195\n",
            "Epoch 21/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1275 - accuracy: 0.9507 - val_loss: 0.2382 - val_accuracy: 0.9188\n",
            "Epoch 22/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1202 - accuracy: 0.9528 - val_loss: 0.2101 - val_accuracy: 0.9231\n",
            "Epoch 23/100\n",
            "754/754 [==============================] - 3s 5ms/step - loss: 0.1151 - accuracy: 0.9539 - val_loss: 0.2424 - val_accuracy: 0.9257\n",
            "Epoch 24/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1085 - accuracy: 0.9578 - val_loss: 0.2428 - val_accuracy: 0.9264\n",
            "Epoch 25/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1115 - accuracy: 0.9570 - val_loss: 0.2376 - val_accuracy: 0.9262\n",
            "Epoch 26/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1030 - accuracy: 0.9601 - val_loss: 0.2542 - val_accuracy: 0.9204\n",
            "Epoch 27/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.1059 - accuracy: 0.9584 - val_loss: 0.2829 - val_accuracy: 0.9124\n",
            "Epoch 28/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0965 - accuracy: 0.9631 - val_loss: 0.2491 - val_accuracy: 0.9279\n",
            "Epoch 29/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0917 - accuracy: 0.9636 - val_loss: 0.2500 - val_accuracy: 0.9167\n",
            "Epoch 30/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0899 - accuracy: 0.9652 - val_loss: 0.3024 - val_accuracy: 0.9236\n",
            "Epoch 31/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0947 - accuracy: 0.9646 - val_loss: 0.2773 - val_accuracy: 0.9289\n",
            "Epoch 32/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0840 - accuracy: 0.9677 - val_loss: 0.3105 - val_accuracy: 0.9242\n",
            "Epoch 33/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0966 - accuracy: 0.9636 - val_loss: 0.2687 - val_accuracy: 0.9223\n",
            "Epoch 34/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0818 - accuracy: 0.9686 - val_loss: 0.3054 - val_accuracy: 0.9277\n",
            "Epoch 35/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0716 - accuracy: 0.9718 - val_loss: 0.3019 - val_accuracy: 0.9219\n",
            "Epoch 36/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0705 - accuracy: 0.9733 - val_loss: 0.2928 - val_accuracy: 0.9158\n",
            "Epoch 37/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0754 - accuracy: 0.9705 - val_loss: 0.3305 - val_accuracy: 0.9257\n",
            "Epoch 38/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0690 - accuracy: 0.9735 - val_loss: 0.3172 - val_accuracy: 0.9171\n",
            "Epoch 39/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0712 - accuracy: 0.9734 - val_loss: 0.2991 - val_accuracy: 0.9294\n",
            "Epoch 40/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0692 - accuracy: 0.9732 - val_loss: 0.3105 - val_accuracy: 0.9150\n",
            "Epoch 41/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0627 - accuracy: 0.9758 - val_loss: 0.3048 - val_accuracy: 0.9298\n",
            "Epoch 42/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0668 - accuracy: 0.9747 - val_loss: 0.3165 - val_accuracy: 0.9300\n",
            "Epoch 43/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0630 - accuracy: 0.9769 - val_loss: 0.3371 - val_accuracy: 0.9277\n",
            "Epoch 44/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0601 - accuracy: 0.9771 - val_loss: 0.3501 - val_accuracy: 0.9210\n",
            "Epoch 45/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0575 - accuracy: 0.9786 - val_loss: 0.3584 - val_accuracy: 0.9283\n",
            "Epoch 46/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0549 - accuracy: 0.9795 - val_loss: 0.3742 - val_accuracy: 0.9277\n",
            "Epoch 47/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0760 - accuracy: 0.9726 - val_loss: 0.3352 - val_accuracy: 0.9242\n",
            "Epoch 48/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0572 - accuracy: 0.9782 - val_loss: 0.3389 - val_accuracy: 0.9311\n",
            "Epoch 49/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0440 - accuracy: 0.9827 - val_loss: 0.3885 - val_accuracy: 0.9264\n",
            "Epoch 50/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0571 - accuracy: 0.9788 - val_loss: 0.3253 - val_accuracy: 0.9216\n",
            "Epoch 51/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0485 - accuracy: 0.9820 - val_loss: 0.3870 - val_accuracy: 0.9238\n",
            "Epoch 52/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 0.3695 - val_accuracy: 0.9287\n",
            "Epoch 53/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0528 - accuracy: 0.9807 - val_loss: 0.3595 - val_accuracy: 0.9117\n",
            "Epoch 54/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0618 - accuracy: 0.9780 - val_loss: 0.3592 - val_accuracy: 0.9270\n",
            "Epoch 55/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.4307 - val_accuracy: 0.9206\n",
            "Epoch 56/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0454 - accuracy: 0.9833 - val_loss: 0.3898 - val_accuracy: 0.9244\n",
            "Epoch 57/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0523 - accuracy: 0.9809 - val_loss: 0.3980 - val_accuracy: 0.9236\n",
            "Epoch 58/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0395 - accuracy: 0.9849 - val_loss: 0.3809 - val_accuracy: 0.9253\n",
            "Epoch 59/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0458 - accuracy: 0.9824 - val_loss: 0.4279 - val_accuracy: 0.9246\n",
            "Epoch 60/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0483 - accuracy: 0.9826 - val_loss: 0.4153 - val_accuracy: 0.9234\n",
            "Epoch 61/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0461 - accuracy: 0.9836 - val_loss: 0.3929 - val_accuracy: 0.9221\n",
            "Epoch 62/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 0.4855 - val_accuracy: 0.9173\n",
            "Epoch 63/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0588 - accuracy: 0.9786 - val_loss: 0.3804 - val_accuracy: 0.9266\n",
            "Epoch 64/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0354 - accuracy: 0.9868 - val_loss: 0.3992 - val_accuracy: 0.9283\n",
            "Epoch 65/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0470 - accuracy: 0.9833 - val_loss: 0.4133 - val_accuracy: 0.9203\n",
            "Epoch 66/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.4331 - val_accuracy: 0.9242\n",
            "Epoch 67/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0482 - accuracy: 0.9829 - val_loss: 0.4296 - val_accuracy: 0.9247\n",
            "Epoch 68/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.4561 - val_accuracy: 0.9186\n",
            "Epoch 69/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0338 - accuracy: 0.9866 - val_loss: 0.4947 - val_accuracy: 0.9203\n",
            "Epoch 70/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0519 - accuracy: 0.9817 - val_loss: 0.4351 - val_accuracy: 0.9251\n",
            "Epoch 71/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0381 - accuracy: 0.9862 - val_loss: 0.4743 - val_accuracy: 0.9242\n",
            "Epoch 72/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0324 - accuracy: 0.9877 - val_loss: 0.4989 - val_accuracy: 0.9104\n",
            "Epoch 73/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0429 - accuracy: 0.9851 - val_loss: 0.4424 - val_accuracy: 0.9098\n",
            "Epoch 74/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0419 - accuracy: 0.9847 - val_loss: 0.4461 - val_accuracy: 0.9294\n",
            "Epoch 75/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.9865 - val_loss: 0.4272 - val_accuracy: 0.9309\n",
            "Epoch 76/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0286 - accuracy: 0.9893 - val_loss: 0.4726 - val_accuracy: 0.9232\n",
            "Epoch 77/100\n",
            "754/754 [==============================] - 4s 5ms/step - loss: 0.0361 - accuracy: 0.9867 - val_loss: 0.4855 - val_accuracy: 0.9221\n",
            "Epoch 78/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0500 - accuracy: 0.9829 - val_loss: 0.4204 - val_accuracy: 0.9216\n",
            "Epoch 79/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.3906 - val_accuracy: 0.9203\n",
            "Epoch 80/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0299 - accuracy: 0.9888 - val_loss: 0.4547 - val_accuracy: 0.9232\n",
            "Epoch 81/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.4543 - val_accuracy: 0.9303\n",
            "Epoch 82/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0573 - accuracy: 0.9812 - val_loss: 0.4137 - val_accuracy: 0.9317\n",
            "Epoch 83/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0287 - accuracy: 0.9895 - val_loss: 0.4550 - val_accuracy: 0.9232\n",
            "Epoch 84/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0418 - accuracy: 0.9860 - val_loss: 0.4233 - val_accuracy: 0.9236\n",
            "Epoch 85/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0241 - accuracy: 0.9905 - val_loss: 0.4631 - val_accuracy: 0.9253\n",
            "Epoch 86/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9877 - val_loss: 0.4944 - val_accuracy: 0.9240\n",
            "Epoch 87/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0338 - accuracy: 0.9879 - val_loss: 0.4797 - val_accuracy: 0.9259\n",
            "Epoch 88/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.4455 - val_accuracy: 0.9289\n",
            "Epoch 89/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 0.4386 - val_accuracy: 0.9298\n",
            "Epoch 90/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0254 - accuracy: 0.9906 - val_loss: 0.4753 - val_accuracy: 0.9223\n",
            "Epoch 91/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.4888 - val_accuracy: 0.9275\n",
            "Epoch 92/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0267 - accuracy: 0.9900 - val_loss: 0.5463 - val_accuracy: 0.9234\n",
            "Epoch 93/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.4932 - val_accuracy: 0.9244\n",
            "Epoch 94/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0359 - accuracy: 0.9877 - val_loss: 0.4861 - val_accuracy: 0.9307\n",
            "Epoch 95/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0328 - accuracy: 0.9885 - val_loss: 0.5149 - val_accuracy: 0.9191\n",
            "Epoch 96/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.4818 - val_accuracy: 0.9294\n",
            "Epoch 97/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.4637 - val_accuracy: 0.9322\n",
            "Epoch 98/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.5243 - val_accuracy: 0.9285\n",
            "Epoch 99/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 0.4737 - val_accuracy: 0.9219\n",
            "Epoch 100/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0190 - accuracy: 0.9930 - val_loss: 0.5389 - val_accuracy: 0.9236\n",
            "Evaluating the model using 13388 samples...\n",
            "Loss: 0.6269\n",
            "Accuracy: 91.51%\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "# train the model using the training set and validating using validation set\n",
        "model2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# save the model to a file\n",
        "\n",
        "#model.save(\"results/model.h5\")  \n",
        "\n",
        "# evaluating the model using the testing set\n",
        "print(f\"Evaluating the model using {len(X_test)} samples...\")\n",
        "loss, accuracy = model2.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(64, 12, 12, 1)]         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (64, 10, 10, 64)          640       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (64, 5, 5, 64)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (64, 4, 4, 128)           32896     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (64, 2, 2, 128)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (64, 2, 2, 256)           33024     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (64, 1, 1, 256)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (64, 256)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (64, 512)                 131584    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (64, 1)                   513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 198657 (776.00 KB)\n",
            "Trainable params: 198657 (776.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# using binary crossentropy as it's male/female classification (binary)\n",
        "inputs = tf.keras.Input(shape=(X.shape[1], X.shape[2], X.shape[3]), batch_size = 64)\n",
        "\n",
        "x3 = tf.keras.layers.Conv2D(64, 3, activation='relu')(inputs)\n",
        "x3 = tf.keras.layers.MaxPooling2D()(x3)\n",
        "\n",
        "x3 = tf.keras.layers.Conv2D(128, 2, activation='relu')(x3)\n",
        "x3 = tf.keras.layers.MaxPooling2D()(x3)\n",
        "\n",
        "x3 = tf.keras.layers.Flatten()(x3)\n",
        "\n",
        "x3 = tf.keras.layers.Dense(256, activation='relu')(x3)\n",
        "\n",
        "outputs3 = tf.keras.layers.Dense(1, activation='sigmoid')(x3)\n",
        "\n",
        "model3 = tf.keras.Model(inputs, outputs3)\n",
        "model3.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
        "# print summary of the model\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.4522 - accuracy: 0.7984 - val_loss: 0.3482 - val_accuracy: 0.8596\n",
            "Epoch 2/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.3237 - accuracy: 0.8610 - val_loss: 0.2957 - val_accuracy: 0.8766\n",
            "Epoch 3/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.2854 - accuracy: 0.8809 - val_loss: 0.2754 - val_accuracy: 0.8915\n",
            "Epoch 4/100\n",
            "754/754 [==============================] - 3s 3ms/step - loss: 0.2574 - accuracy: 0.8948 - val_loss: 0.2370 - val_accuracy: 0.9120\n",
            "Epoch 5/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.2370 - accuracy: 0.9039 - val_loss: 0.2384 - val_accuracy: 0.9053\n",
            "Epoch 6/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.2239 - accuracy: 0.9113 - val_loss: 0.2140 - val_accuracy: 0.9195\n",
            "Epoch 7/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.2110 - accuracy: 0.9170 - val_loss: 0.2052 - val_accuracy: 0.9210\n",
            "Epoch 8/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.2000 - accuracy: 0.9228 - val_loss: 0.1997 - val_accuracy: 0.9206\n",
            "Epoch 9/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1906 - accuracy: 0.9276 - val_loss: 0.1956 - val_accuracy: 0.9218\n",
            "Epoch 10/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1801 - accuracy: 0.9305 - val_loss: 0.1964 - val_accuracy: 0.9261\n",
            "Epoch 11/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1749 - accuracy: 0.9324 - val_loss: 0.2166 - val_accuracy: 0.9253\n",
            "Epoch 12/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1650 - accuracy: 0.9379 - val_loss: 0.2006 - val_accuracy: 0.9272\n",
            "Epoch 13/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1614 - accuracy: 0.9385 - val_loss: 0.2023 - val_accuracy: 0.9274\n",
            "Epoch 14/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1515 - accuracy: 0.9418 - val_loss: 0.2158 - val_accuracy: 0.9227\n",
            "Epoch 15/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1441 - accuracy: 0.9447 - val_loss: 0.1989 - val_accuracy: 0.9262\n",
            "Epoch 16/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1433 - accuracy: 0.9452 - val_loss: 0.1980 - val_accuracy: 0.9326\n",
            "Epoch 17/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1345 - accuracy: 0.9489 - val_loss: 0.2044 - val_accuracy: 0.9292\n",
            "Epoch 18/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1377 - accuracy: 0.9470 - val_loss: 0.1958 - val_accuracy: 0.9322\n",
            "Epoch 19/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1277 - accuracy: 0.9521 - val_loss: 0.2130 - val_accuracy: 0.9330\n",
            "Epoch 20/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1275 - accuracy: 0.9516 - val_loss: 0.2087 - val_accuracy: 0.9322\n",
            "Epoch 21/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1117 - accuracy: 0.9584 - val_loss: 0.2082 - val_accuracy: 0.9315\n",
            "Epoch 22/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1102 - accuracy: 0.9581 - val_loss: 0.2106 - val_accuracy: 0.9279\n",
            "Epoch 23/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1179 - accuracy: 0.9554 - val_loss: 0.2221 - val_accuracy: 0.9277\n",
            "Epoch 24/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.1132 - accuracy: 0.9573 - val_loss: 0.2215 - val_accuracy: 0.9331\n",
            "Epoch 25/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0982 - accuracy: 0.9629 - val_loss: 0.2004 - val_accuracy: 0.9376\n",
            "Epoch 26/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0919 - accuracy: 0.9649 - val_loss: 0.2228 - val_accuracy: 0.9371\n",
            "Epoch 27/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0935 - accuracy: 0.9648 - val_loss: 0.2232 - val_accuracy: 0.9373\n",
            "Epoch 28/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0945 - accuracy: 0.9643 - val_loss: 0.2290 - val_accuracy: 0.9337\n",
            "Epoch 29/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0906 - accuracy: 0.9664 - val_loss: 0.2416 - val_accuracy: 0.9298\n",
            "Epoch 30/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0799 - accuracy: 0.9708 - val_loss: 0.2282 - val_accuracy: 0.9317\n",
            "Epoch 31/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0832 - accuracy: 0.9685 - val_loss: 0.2392 - val_accuracy: 0.9322\n",
            "Epoch 32/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0884 - accuracy: 0.9672 - val_loss: 0.2716 - val_accuracy: 0.9300\n",
            "Epoch 33/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0749 - accuracy: 0.9725 - val_loss: 0.2563 - val_accuracy: 0.9376\n",
            "Epoch 34/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0712 - accuracy: 0.9734 - val_loss: 0.2580 - val_accuracy: 0.9352\n",
            "Epoch 35/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0792 - accuracy: 0.9703 - val_loss: 0.2503 - val_accuracy: 0.9318\n",
            "Epoch 36/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0735 - accuracy: 0.9717 - val_loss: 0.2655 - val_accuracy: 0.9335\n",
            "Epoch 37/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0683 - accuracy: 0.9750 - val_loss: 0.2379 - val_accuracy: 0.9352\n",
            "Epoch 38/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0592 - accuracy: 0.9777 - val_loss: 0.2791 - val_accuracy: 0.9371\n",
            "Epoch 39/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0569 - accuracy: 0.9791 - val_loss: 0.2754 - val_accuracy: 0.9339\n",
            "Epoch 40/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0611 - accuracy: 0.9771 - val_loss: 0.2788 - val_accuracy: 0.9317\n",
            "Epoch 41/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0732 - accuracy: 0.9739 - val_loss: 0.2609 - val_accuracy: 0.9380\n",
            "Epoch 42/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0551 - accuracy: 0.9794 - val_loss: 0.3095 - val_accuracy: 0.9376\n",
            "Epoch 43/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0575 - accuracy: 0.9788 - val_loss: 0.3003 - val_accuracy: 0.9328\n",
            "Epoch 44/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0674 - accuracy: 0.9758 - val_loss: 0.2730 - val_accuracy: 0.9380\n",
            "Epoch 45/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 0.3344 - val_accuracy: 0.9326\n",
            "Epoch 46/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0699 - accuracy: 0.9754 - val_loss: 0.3006 - val_accuracy: 0.9298\n",
            "Epoch 47/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0522 - accuracy: 0.9803 - val_loss: 0.3176 - val_accuracy: 0.9313\n",
            "Epoch 48/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0427 - accuracy: 0.9841 - val_loss: 0.3009 - val_accuracy: 0.9376\n",
            "Epoch 49/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0612 - accuracy: 0.9779 - val_loss: 0.2910 - val_accuracy: 0.9339\n",
            "Epoch 50/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0500 - accuracy: 0.9824 - val_loss: 0.2840 - val_accuracy: 0.9296\n",
            "Epoch 51/100\n",
            "754/754 [==============================] - 3s 4ms/step - loss: 0.0517 - accuracy: 0.9809 - val_loss: 0.3186 - val_accuracy: 0.9346\n",
            "Epoch 52/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0377 - accuracy: 0.9860 - val_loss: 0.2942 - val_accuracy: 0.9404\n",
            "Epoch 53/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.3478 - val_accuracy: 0.9335\n",
            "Epoch 54/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0679 - accuracy: 0.9774 - val_loss: 0.3197 - val_accuracy: 0.9283\n",
            "Epoch 55/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0450 - accuracy: 0.9831 - val_loss: 0.3377 - val_accuracy: 0.9350\n",
            "Epoch 56/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.3490 - val_accuracy: 0.9333\n",
            "Epoch 57/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0299 - accuracy: 0.9886 - val_loss: 0.3585 - val_accuracy: 0.9346\n",
            "Epoch 58/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0654 - accuracy: 0.9790 - val_loss: 0.3482 - val_accuracy: 0.9257\n",
            "Epoch 59/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0455 - accuracy: 0.9838 - val_loss: 0.3257 - val_accuracy: 0.9365\n",
            "Epoch 60/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0403 - accuracy: 0.9854 - val_loss: 0.3573 - val_accuracy: 0.9331\n",
            "Epoch 61/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 0.3707 - val_accuracy: 0.9331\n",
            "Epoch 62/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0343 - accuracy: 0.9871 - val_loss: 0.4089 - val_accuracy: 0.9341\n",
            "Epoch 63/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0471 - accuracy: 0.9833 - val_loss: 0.3835 - val_accuracy: 0.9339\n",
            "Epoch 64/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0538 - accuracy: 0.9823 - val_loss: 0.3694 - val_accuracy: 0.9345\n",
            "Epoch 65/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0357 - accuracy: 0.9874 - val_loss: 0.3629 - val_accuracy: 0.9365\n",
            "Epoch 66/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.4057 - val_accuracy: 0.9303\n",
            "Epoch 67/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.4251 - val_accuracy: 0.9350\n",
            "Epoch 68/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0237 - accuracy: 0.9910 - val_loss: 0.4147 - val_accuracy: 0.9335\n",
            "Epoch 69/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0480 - accuracy: 0.9844 - val_loss: 0.4699 - val_accuracy: 0.9251\n",
            "Epoch 70/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0408 - accuracy: 0.9854 - val_loss: 0.4013 - val_accuracy: 0.9337\n",
            "Epoch 71/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0378 - accuracy: 0.9868 - val_loss: 0.4032 - val_accuracy: 0.9309\n",
            "Epoch 72/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0325 - accuracy: 0.9889 - val_loss: 0.4199 - val_accuracy: 0.9331\n",
            "Epoch 73/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.4109 - val_accuracy: 0.9373\n",
            "Epoch 74/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.4735 - val_accuracy: 0.9337\n",
            "Epoch 75/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0483 - accuracy: 0.9841 - val_loss: 0.4228 - val_accuracy: 0.9382\n",
            "Epoch 76/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 0.4118 - val_accuracy: 0.9307\n",
            "Epoch 77/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.4334 - val_accuracy: 0.9337\n",
            "Epoch 78/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0212 - accuracy: 0.9920 - val_loss: 0.4258 - val_accuracy: 0.9401\n",
            "Epoch 79/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 0.4914 - val_accuracy: 0.9374\n",
            "Epoch 80/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.4313 - val_accuracy: 0.9337\n",
            "Epoch 81/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0243 - accuracy: 0.9910 - val_loss: 0.4275 - val_accuracy: 0.9367\n",
            "Epoch 82/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 0.5046 - val_accuracy: 0.9361\n",
            "Epoch 83/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0435 - accuracy: 0.9856 - val_loss: 0.4181 - val_accuracy: 0.9378\n",
            "Epoch 84/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.4264 - val_accuracy: 0.9324\n",
            "Epoch 85/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.4696 - val_accuracy: 0.9361\n",
            "Epoch 86/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0340 - accuracy: 0.9879 - val_loss: 0.5149 - val_accuracy: 0.9318\n",
            "Epoch 87/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 0.4082 - val_accuracy: 0.9369\n",
            "Epoch 88/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0320 - accuracy: 0.9894 - val_loss: 0.4759 - val_accuracy: 0.9402\n",
            "Epoch 89/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.5150 - val_accuracy: 0.9331\n",
            "Epoch 90/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0400 - accuracy: 0.9871 - val_loss: 0.4161 - val_accuracy: 0.9333\n",
            "Epoch 91/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 0.5132 - val_accuracy: 0.9391\n",
            "Epoch 92/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.4668 - val_accuracy: 0.9374\n",
            "Epoch 93/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 0.4841 - val_accuracy: 0.9326\n",
            "Epoch 94/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: 0.4700 - val_accuracy: 0.9343\n",
            "Epoch 95/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0231 - accuracy: 0.9913 - val_loss: 0.5480 - val_accuracy: 0.9374\n",
            "Epoch 96/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.4945 - val_accuracy: 0.9378\n",
            "Epoch 97/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.5263 - val_accuracy: 0.9363\n",
            "Epoch 98/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.4837 - val_accuracy: 0.9358\n",
            "Epoch 99/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.5390 - val_accuracy: 0.9307\n",
            "Epoch 100/100\n",
            "754/754 [==============================] - 2s 3ms/step - loss: 0.0275 - accuracy: 0.9903 - val_loss: 0.4743 - val_accuracy: 0.9373\n",
            "Evaluating the model using 13388 samples...\n",
            "Loss: 0.5713\n",
            "Accuracy: 93.13%\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "# train the model using the training set and validating using validation set\n",
        "model3.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# save the model to a file\n",
        "\n",
        "model3.save(\"results/model.h5\")  \n",
        "\n",
        "# evaluating the model using the testing set\n",
        "print(f\"Evaluating the model using {len(X_test)} samples...\")\n",
        "loss, accuracy = model3.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Demo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wavio\n",
            "  Downloading wavio-0.0.8-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from wavio) (1.26.2)\n",
            "Downloading wavio-0.0.8-py3-none-any.whl (9.4 kB)\n",
            "Installing collected packages: wavio\n",
            "Successfully installed wavio-0.0.8\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install wavio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sounddevice as sd\n",
        "import wavio\n",
        "import scipy.stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0 Rakhat’s iPhone Microphone, Core Audio (1 in, 0 out)\n",
            "> 1 MacBook Pro Microphone, Core Audio (1 in, 0 out)\n",
            "< 2 MacBook Pro Speakers, Core Audio (0 in, 2 out)\n",
            "  3 BoomAudio, Core Audio (6 in, 6 out)\n",
            "  4 Microsoft Teams Audio, Core Audio (2 in, 2 out)\n"
          ]
        }
      ],
      "source": [
        "# def record_audio(duration=5, filename='recorded_voice.wav', fs=44100):\n",
        "#     print(\"Recording...\")\n",
        "#     audio = sd.rec(int(duration * fs), samplerate=fs, channels=2)\n",
        "#     sd.wait()  # Wait until recording is finished\n",
        "#     print(\"Recording finished. Saving file...\")\n",
        "#     wavio.write(filename, audio, fs, sampwidth=2)  # Save as WAV file\n",
        "#     return filename\n",
        "\n",
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "def list_devices():\n",
        "    \"\"\"\n",
        "    List all available audio input and output devices.\n",
        "    \"\"\"\n",
        "    print(sd.query_devices())\n",
        "\n",
        "def record_audio(duration=5, fs=44100, channels=1, filename='recorded_voice.wav'):\n",
        "    \"\"\"\n",
        "    Record audio for a given duration, sample rate, and number of channels.\n",
        "    \n",
        "    :param duration: Duration in seconds\n",
        "    :param fs: Sampling rate\n",
        "    :param channels: Number of audio channels\n",
        "    :return: NumPy array of recorded audio\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"Recording...\")\n",
        "        recording = sd.rec(int(duration * fs), samplerate=fs, channels=channels)\n",
        "        sd.wait()  # Wait until recording is finished\n",
        "        print(\"Recording complete\")\n",
        "        print(\"Recording finished. Saving file...\")\n",
        "        wavio.write(filename, recording, fs, sampwidth=2)\n",
        "        return recording\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# List available devices\n",
        "list_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    \"\"\"\n",
        "    Extract feature from audio file `file_name`\n",
        "        Features supported:\n",
        "            - MFCC (mfcc)\n",
        "            - Chroma (chroma)\n",
        "            - MEL Spectrogram Frequency (mel)\n",
        "            - Contrast (contrast)\n",
        "            - Tonnetz (tonnetz)\n",
        "        e.g:\n",
        "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
        "    \"\"\"\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    X, sample_rate = librosa.core.load(file_name)\n",
        "    if chroma or contrast:\n",
        "        stft = np.abs(librosa.stft(X))\n",
        "    result = np.array([])\n",
        "    if mfcc:\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        result = np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, mel))\n",
        "    if contrast:\n",
        "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, contrast))\n",
        "    if tonnetz:\n",
        "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, tonnetz))\n",
        "    #result = np.hstack((result, np.zeros(1, 16)))\n",
        "    for i in range(16):\n",
        "        result = np.hstack((result, 0))\n",
        "    #print(result.shape)\n",
        "    #print(result)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ffmpeg in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'record_audio' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example usage - try changing channels if needed\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m audio_data \u001b[39m=\u001b[39m record_audio(duration\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, fs\u001b[39m=\u001b[39m\u001b[39m44100\u001b[39m, channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m features \u001b[39m=\u001b[39m extract_feature(audio_data, mel\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m12\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'record_audio' is not defined"
          ]
        }
      ],
      "source": [
        "# Example usage - try changing channels if needed\n",
        "audio_data = record_audio(duration=5, fs=44100, channels=1)\n",
        "features = extract_feature(file, mel=True)\n",
        "    \n",
        "features = features.reshape(-1, 12, 12)\n",
        "#print(features)\n",
        "features = np.expand_dims(features, axis=3)\n",
        "#print(model.predict(features))\n",
        "male_prob = model3.predict(features)[0][0]\n",
        "female_prob = 1 - male_prob\n",
        "gender = \"male\" if male_prob > female_prob else \"female\"\n",
        "# show the result!\n",
        "print(\"Result:\", gender)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1_/pw0_qvk92kxcltkjvbtqf73w0000gn/T/ipykernel_29818/3010357707.py:130: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  X, sample_rate = librosa.core.load(file_name)\n"
          ]
        },
        {
          "ename": "NoBackendError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/core/audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    177\u001b[0m \u001b[39mexcept\u001b[39;00m sf\u001b[39m.\u001b[39mSoundFileRuntimeError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    178\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/core/audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[1;32m    210\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/Users/rakhatmyrzakhan/Library/Jupyter/runtime/kernel-v2-17648FHxUUC3Sck9U.json': Format not recognised.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m     record_to_file(file)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m \u001b[39m# extract features and reshape it\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m features \u001b[39m=\u001b[39m extract_feature(file, mel\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m12\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m \u001b[39m#print(features)\u001b[39;00m\n",
            "\u001b[1;32m/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m contrast \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontrast\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m tonnetz \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtonnetz\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m X, sample_rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39;49mload(file_name)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39mif\u001b[39;00m chroma \u001b[39mor\u001b[39;00m contrast:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rakhatmyrzakhan/Desktop/dldl/DL_project.ipynb#X26sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m     stft \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(librosa\u001b[39m.\u001b[39mstft(X))\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/core/audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    180\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/util/decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     52\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mDeprecated as of librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mIt will be removed in librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,  \u001b[39m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/core/audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    236\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[1;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[1;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    242\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/audioread/__init__.py:132\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m# All backends failed!\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[39mraise\u001b[39;00m NoBackendError()\n",
            "\u001b[0;31mNoBackendError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "THRESHOLD = 500\n",
        "CHUNK_SIZE = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "RATE = 16000\n",
        "\n",
        "SILENCE = 30\n",
        "\n",
        "def is_silent(snd_data):\n",
        "    \"Returns 'True' if below the 'silent' threshold\"\n",
        "    return max(snd_data) < THRESHOLD\n",
        "\n",
        "def normalize(snd_data):\n",
        "    \"Average the volume out\"\n",
        "    MAXIMUM = 16384\n",
        "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
        "\n",
        "    r = array('h')\n",
        "    for i in snd_data:\n",
        "        r.append(int(i*times))\n",
        "    return r\n",
        "\n",
        "def trim(snd_data):\n",
        "    \"Trim the blank spots at the start and end\"\n",
        "    def _trim(snd_data):\n",
        "        snd_started = False\n",
        "        r = array('h')\n",
        "\n",
        "        for i in snd_data:\n",
        "            if not snd_started and abs(i)>THRESHOLD:\n",
        "                snd_started = True\n",
        "                r.append(i)\n",
        "\n",
        "            elif snd_started:\n",
        "                r.append(i)\n",
        "        return r\n",
        "\n",
        "    # Trim to the left\n",
        "    snd_data = _trim(snd_data)\n",
        "\n",
        "    # Trim to the right\n",
        "    snd_data.reverse()\n",
        "    snd_data = _trim(snd_data)\n",
        "    snd_data.reverse()\n",
        "    return snd_data\n",
        "\n",
        "def add_silence(snd_data, seconds):\n",
        "    \"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\n",
        "    r = array('h', [0 for i in range(int(seconds*RATE))])\n",
        "    r.extend(snd_data)\n",
        "    r.extend([0 for i in range(int(seconds*RATE))])\n",
        "    return r\n",
        "\n",
        "def record():\n",
        "    \"\"\"\n",
        "    Record a word or words from the microphone and \n",
        "    return the data as an array of signed shorts.\n",
        "    Normalizes the audio, trims silence from the \n",
        "    start and end, and pads with 0.5 seconds of \n",
        "    blank sound to make sure VLC et al can play \n",
        "    it without getting chopped off.\n",
        "    \"\"\"\n",
        "    p = pyaudio.PyAudio()\n",
        "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
        "        input=True, output=True,\n",
        "        frames_per_buffer=CHUNK_SIZE)\n",
        "\n",
        "    num_silent = 0\n",
        "    snd_started = False\n",
        "\n",
        "    r = array('h')\n",
        "\n",
        "    while 1:\n",
        "        # little endian, signed short\n",
        "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
        "        if byteorder == 'big':\n",
        "            snd_data.byteswap()\n",
        "        r.extend(snd_data)\n",
        "\n",
        "        silent = is_silent(snd_data)\n",
        "\n",
        "        if silent and snd_started:\n",
        "            num_silent += 1\n",
        "        elif not silent and not snd_started:\n",
        "            snd_started = True\n",
        "\n",
        "        if snd_started and num_silent > SILENCE:\n",
        "            break\n",
        "\n",
        "    sample_width = p.get_sample_size(FORMAT)\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()\n",
        "\n",
        "    r = normalize(r)\n",
        "    r = trim(r)\n",
        "    r = add_silence(r, 0.5)\n",
        "    return sample_width, r\n",
        "\n",
        "def record_to_file(path):\n",
        "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
        "    sample_width, data = record()\n",
        "    data = pack('<' + ('h'*len(data)), *data)\n",
        "\n",
        "    wf = wave.open(path, 'wb')\n",
        "    wf.setnchannels(1)\n",
        "    wf.setsampwidth(sample_width)\n",
        "    wf.setframerate(RATE)\n",
        "    wf.writeframes(data)\n",
        "    wf.close()\n",
        "\n",
        "\n",
        "\n",
        "def extract_feature(file_name, **kwargs):\n",
        "    \"\"\"\n",
        "    Extract feature from audio file `file_name`\n",
        "        Features supported:\n",
        "            - MFCC (mfcc)\n",
        "            - Chroma (chroma)\n",
        "            - MEL Spectrogram Frequency (mel)\n",
        "            - Contrast (contrast)\n",
        "            - Tonnetz (tonnetz)\n",
        "        e.g:\n",
        "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
        "    \"\"\"\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    X, sample_rate = librosa.core.load(file_name)\n",
        "    if chroma or contrast:\n",
        "        stft = np.abs(librosa.stft(X))\n",
        "    result = np.array([])\n",
        "    if mfcc:\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        result = np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, mel))\n",
        "    if contrast:\n",
        "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, contrast))\n",
        "    if tonnetz:\n",
        "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, tonnetz))\n",
        "    #result = np.hstack((result, np.zeros(1, 16)))\n",
        "    for i in range(16):\n",
        "        result = np.hstack((result, 0))\n",
        "    #print(result.shape)\n",
        "    #print(result)\n",
        "    return result\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # load the saved model (after training)\n",
        "    # model = pickle.load(open(\"result/mlp_classifier.model\", \"rb\"))\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
        "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
        "    parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
        "    args = parser.parse_args()\n",
        "    file = args.file\n",
        "    #model3.load_weights(\"results/model.h5\")\n",
        "    # construct the model\n",
        "    # load the saved/trained weight\n",
        "    #print(model)\n",
        "    if not file or not os.path.isfile(file):\n",
        "        # if file not provided, or it doesn't exist, use your voice\n",
        "        print(\"Please talk\")\n",
        "        # put the file name here\n",
        "        file = \"test.wav\"\n",
        "        # record the file (start talking)\n",
        "        record_to_file(file)\n",
        "    # extract features and reshape it\n",
        "    features = extract_feature(file, mel=True)\n",
        "    \n",
        "    features = features.reshape(-1, 12, 12)\n",
        "    #print(features)\n",
        "    features = np.expand_dims(features, axis=3)\n",
        "    #print(model.predict(features))\n",
        "    male_prob = model3.predict(features)[0][0]\n",
        "    female_prob = 1 - male_prob\n",
        "    gender = \"male\" if male_prob > female_prob else \"female\"\n",
        "    # show the result!\n",
        "    print(\"Result:\", gender)\n",
        "    ##print(f\"Probabilities:     Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
